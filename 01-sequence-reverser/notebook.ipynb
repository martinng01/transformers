{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wsiMT242Wya"
      },
      "source": [
        "## Generate dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BFuL35BJuY4C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def gen_dataset(n_samples, seq_len, vocab_size):\n",
        "    X = np.random.randint(1, vocab_size, size=(n_samples, seq_len))\n",
        "    Y = np.flip(X, axis=1)\n",
        "\n",
        "    return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "G6kTQLZ6BDu5"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "vocab_size = 99\n",
        "d_model = 128\n",
        "seq_len = 10\n",
        "num_heads = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hL0D75C06Yeo"
      },
      "outputs": [],
      "source": [
        "X, Y = gen_dataset(\n",
        "    n_samples=20000,\n",
        "    seq_len=seq_len,\n",
        "    vocab_size=vocab_size\n",
        ")\n",
        "\n",
        "train_end = int(0.8 * len(X))\n",
        "val_end = int(0.9 * len(X))\n",
        "\n",
        "# (n_samples, seq_len)\n",
        "X_train, Y_train = X[:train_end], Y[:train_end]\n",
        "X_val, Y_val = X[train_end: val_end], Y[train_end:val_end]\n",
        "X_test, Y_test = X[val_end:], Y[val_end:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUg9ebhBCtAi"
      },
      "source": [
        "## Embedding layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "a8pAbrElAaA7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "# Initialised randomly from N(0, 1)\n",
        "# (vocab_size, d_model)\n",
        "embedding = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "# \"Attention Is All You Need\" S3.4: \"In the embedding layers, we multiply those weights by âˆšdmodel\"\n",
        "# (n_samples, seq_len, d_model)\n",
        "emb = embedding(torch.from_numpy(X_train)) * math.sqrt(d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Positional Encoding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "_6ceBsVoBVEv"
      },
      "outputs": [],
      "source": [
        "# (seq_len, d_model)\n",
        "def get_positional_encoding(seq_len, d_model):\n",
        "    pe = torch.zeros(seq_len, d_model)\n",
        "\n",
        "    # (1, d_model // 2)\n",
        "    # i has to represent the columns in the final matrix, therefore unsqueeze 0\n",
        "    i = torch.arange(0, d_model // 2).unsqueeze(0)\n",
        "\n",
        "    # (seq_len, 1)\n",
        "    pos = torch.arange(0, seq_len).unsqueeze(1)\n",
        "\n",
        "    # (seq_len, d_model // 2)\n",
        "    term = pos / torch.pow(10000, 2 * i / d_model)\n",
        "\n",
        "    pe[:, 0::2] = torch.sin(term)\n",
        "    pe[:, 1::2] = torch.cos(term)\n",
        "\n",
        "    return pe\n",
        "\n",
        "\n",
        "pe = get_positional_encoding(seq_len, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, seq_len, d_model):\n",
        "        super().__init__()\n",
        "\n",
        "        pe = torch.zeros(seq_len, d_model)\n",
        "\n",
        "        # (1, d_model // 2)\n",
        "        # i has to represent the columns in the final matrix, therefore unsqueeze 0\n",
        "        i = torch.arange(0, d_model // 2).unsqueeze(0)\n",
        "\n",
        "        # (seq_len, 1)\n",
        "        pos = torch.arange(0, seq_len).unsqueeze(1)\n",
        "\n",
        "        # (seq_len, d_model // 2)\n",
        "        term = pos / torch.pow(10000, 2 * i / d_model)\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(term)\n",
        "        pe[:, 1::2] = torch.cos(term)\n",
        "\n",
        "        pe = pe.unsqueeze(0)\n",
        "\n",
        "        # Move to gpu for the below x + self.pe operation\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # n_samples, seq_len, d_model\n",
        "        return x + self.pe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sum\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "MVMAn1A_BaY1"
      },
      "outputs": [],
      "source": [
        "# (n_samples, seq_len, d_model)\n",
        "x = emb + pe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multihead Attention\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, h):\n",
        "        super().__init__()\n",
        "        assert d_model % h == 0, \"d_model must be divisible by num_heads\"\n",
        "\n",
        "        self.h = h\n",
        "        self.d_k = d_model // h\n",
        "\n",
        "        self.W_Q = nn.Linear(d_model, d_model)\n",
        "        self.W_K = nn.Linear(d_model, d_model)\n",
        "        self.W_V = nn.Linear(d_model, d_model)\n",
        "        self.W_O = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        n_samples, seq_len, d_model = x.size()\n",
        "\n",
        "        # (n_samples, seq_len, d_model)\n",
        "        Q = self.W_Q(x)\n",
        "        K = self.W_K(x)\n",
        "        V = self.W_V(x)\n",
        "\n",
        "        # (n_samples, seq_len, h, d_k)\n",
        "        Q = Q.view(n_samples, seq_len, self.h, self.d_k)\n",
        "        K = K.view(n_samples, seq_len, self.h, self.d_k)\n",
        "        V = V.view(n_samples, seq_len, self.h, self.d_k)\n",
        "\n",
        "        # Swap h and seq_len, matmul only works on last 2 dimensions\n",
        "        # (n_samples, h, seq_len, d_k)\n",
        "        Q = Q.transpose(1, 2)\n",
        "        K = K.transpose(1, 2)\n",
        "        V = V.transpose(1, 2)\n",
        "\n",
        "        qkt = Q @ K.transpose(2, 3)  # (n_samples, h, seq_len, seq_len)\n",
        "        scaled = qkt / math.sqrt(self.d_k)\n",
        "        weights = F.softmax(scaled, dim=-1)\n",
        "\n",
        "        self.attn_weights = weights\n",
        "\n",
        "        output = weights @ V  # (n_samples, h, seq_len, d_k)\n",
        "\n",
        "        # (n_samples, seq_len, d_model)\n",
        "        concat = output.transpose(1, 2).contiguous().view(\n",
        "            n_samples, seq_len, d_model)\n",
        "\n",
        "        return self.W_O(concat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, d_model, h, d_ff):\n",
        "        super().__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, h)\n",
        "\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(d_ff, d_model)\n",
        "        )\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mha_out = self.mha(x)\n",
        "        x = self.norm1(x + mha_out)\n",
        "\n",
        "        ff_out = self.ff(x)\n",
        "        x = self.norm2(x + ff_out)\n",
        "\n",
        "        # (batch, seq_len, dims)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TransformerReverser(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, seq_len, num_heads, num_layers):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoding = PositionalEncoding(seq_len, d_model)\n",
        "        self.layers = nn.ModuleList([\n",
        "            EncoderBlock(d_model, num_heads, num_heads * 4) for _ in range(num_layers)\n",
        "        ])\n",
        "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.emb(x)\n",
        "        x = self.pos_encoding(x)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "\n",
        "        x = self.fc_out(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "\n",
        "model = TransformerReverser(\n",
        "    vocab_size=vocab_size,\n",
        "    d_model=d_model,\n",
        "    seq_len=seq_len,\n",
        "    num_heads=num_heads,\n",
        "    num_layers=4\n",
        ")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(dataloader, model, criterion, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for inputs, targets in dataloader:\n",
        "        # inputs = (batch, seqlen)\n",
        "        # targets = (batch, seqlen)\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # (batch_size, seq len, vocabsize)\n",
        "        logits = model(inputs)\n",
        "\n",
        "        # CrossEntropyLoss expects (batch, num_classes)\n",
        "        loss = criterion(logits.view(-1, vocab_size), targets.view(-1))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "\n",
        "def eval(dataloader, model, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    # to calculate accuracy\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in dataloader:\n",
        "            # inputs = (batch, seqlen)\n",
        "            # targets = (batch, seqlen)\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # (batch_size, seq len, vocabsize)\n",
        "            logits = model(inputs)\n",
        "\n",
        "            # CrossEntropyLoss expects (batch, num_classes)\n",
        "            loss = criterion(logits.view(-1, vocab_size), targets.view(-1))\n",
        "\n",
        "            # (batch_size, seqlen)\n",
        "            predictions = torch.argmax(logits, dim=-1)\n",
        "            total_loss += loss.item()\n",
        "            correct += (predictions == targets).sum().item()\n",
        "            total += targets.numel()\n",
        "\n",
        "    return total_loss / len(dataloader), (correct / total) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class ReversalDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = torch.tensor(X.copy()).long()\n",
        "        self.Y = torch.tensor(Y.copy()).long()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.Y[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "\n",
        "train_dataset = ReversalDataset(X_train, Y_train)\n",
        "val_dataset = ReversalDataset(X_val, Y_val)\n",
        "test_dataset = ReversalDataset(X_test, Y_test)\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train Loss: 0.9375 | Val Loss: 0.0096 | Val Acc: 99.85%\n",
            "Epoch 02 | Train Loss: 0.0162 | Val Loss: 0.0015 | Val Acc: 100.00%\n",
            "Epoch 03 | Train Loss: 0.0008 | Val Loss: 0.0005 | Val Acc: 100.00%\n",
            "Epoch 04 | Train Loss: 0.0004 | Val Loss: 0.0003 | Val Acc: 100.00%\n",
            "Epoch 05 | Train Loss: 0.0003 | Val Loss: 0.0002 | Val Acc: 100.00%\n",
            "Epoch 06 | Train Loss: 0.0002 | Val Loss: 0.0002 | Val Acc: 100.00%\n",
            "Epoch 07 | Train Loss: 0.0001 | Val Loss: 0.0001 | Val Acc: 100.00%\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[90]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m best_val_loss = \u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33minf\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     train_loss = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     val_loss, val_acc = \u001b[38;5;28meval\u001b[39m(train_loader, model, criterion)\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m val_loss < best_val_loss:\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[88]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(dataloader, model, criterion, optimizer)\u001b[39m\n\u001b[32m     16\u001b[39m     optimizer.zero_grad()\n\u001b[32m     17\u001b[39m     loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m     total_loss += loss.item()\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss / \u001b[38;5;28mlen\u001b[39m(dataloader)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlprep/lib/python3.12/site-packages/torch/optim/optimizer.py:516\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    511\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    512\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    513\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    514\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    519\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlprep/lib/python3.12/site-packages/torch/optim/optimizer.py:81\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     79\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     80\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     83\u001b[39m     torch._dynamo.graph_break()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlprep/lib/python3.12/site-packages/torch/optim/adam.py:247\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    235\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    237\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    238\u001b[39m         group,\n\u001b[32m    239\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    244\u001b[39m         state_steps,\n\u001b[32m    245\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlprep/lib/python3.12/site-packages/torch/optim/optimizer.py:149\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlprep/lib/python3.12/site-packages/torch/optim/adam.py:949\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    946\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    947\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlprep/lib/python3.12/site-packages/torch/optim/adam.py:535\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    533\u001b[39m         denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m     \u001b[43mparam\u001b[49m\u001b[43m.\u001b[49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n\u001b[32m    538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m amsgrad \u001b[38;5;129;01mand\u001b[39;00m torch.is_complex(params[i]):\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "epochs = 20\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train(train_loader, model, criterion, optimizer)\n",
        "    val_loss, val_acc = eval(train_loader, model, criterion)\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), 'best_model.pt')\n",
        "\n",
        "    print(f\"Epoch {epoch+1:02d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:    [0, 12, 14, 16, 18, 20, 22, 24, 26, 28]\n",
            "Reversed: [26, 26, 24, 22, 20, 18, 16, 14, 12, 12]\n"
          ]
        }
      ],
      "source": [
        "def reverse_this(sequence, model, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # 1. Prepare input\n",
        "        x = torch.tensor([sequence]).long().to(device)\n",
        "\n",
        "        # 2. Get prediction\n",
        "        logits = model(x)\n",
        "        preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "        # 3. Convert back to list\n",
        "        return preds.cpu().numpy()[0].tolist()\n",
        "\n",
        "\n",
        "# Try a sequence\n",
        "my_test = [0, 12, 14, 16, 18, 20, 22, 24, 26, 28]\n",
        "result = reverse_this(my_test, model, device)\n",
        "\n",
        "print(f\"Input:    {my_test}\")\n",
        "print(f\"Reversed: {result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Create a placeholder to store the weights\n",
        "saved_attention = {}\n",
        "\n",
        "\n",
        "def hook_fn(m, i, o):\n",
        "    # This grabs the weights from the softmax in your MultiHeadAttention\n",
        "    # We'll need to slightly tweak your MHA to make this variable accessible,\n",
        "    # or just use this trick to grab the output of the softmax specifically.\n",
        "    saved_attention['weights'] = o\n",
        "\n",
        "\n",
        "# 2. Attach the hook to the attention layer of the first block\n",
        "# Assuming your EncoderBlock has an attribute 'mha'\n",
        "handle = model.layers[0].mha.register_forward_hook(hook_fn)\n",
        "\n",
        "# 3. Run the inference again\n",
        "test_seq = torch.tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 5]]).to(device)\n",
        "model(test_seq)\n",
        "\n",
        "# 4. Remove the hook so it doesn't slow down the model later\n",
        "handle.remove()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAHHCAYAAACx2FF+AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAT0VJREFUeJzt3Qd8FHX6+PEnCSTUUEQ6SFV6kXYIigqC/FFBUZHzDkR/nAooyimKShMBQUCkHCiKgEizoWcBEUFFQRAEG4IgJUivoQey8389X2/X3WQD25Kd7Hze95ozOzs7+93Jhme+z7fFWZZlCQAAcIz4aBcAAADkLII/AAAOQ/AHAMBhCP4AADgMwR8AAIch+AMA4DAEfwAAHIbgDwCAwxD8AQBwGII/clxcXJwMGTIk2sUAAMci+Ocy//nPf0zwbNasmd/nf/nlFxNYt2/f7ve1M2bMyIFSinz88ce2C/BaHr128fHxkpKSkun51NRUyZ8/vzmmT58+YrdyHzx4UOxg9+7dpkzr168XO/n666/l1ltvlVKlSklSUpJUqlRJ7r//ftm5c2fI5zx16pT5rMuXLxen/t0gNhH8c5k333zT/KO2evVq2bJli9/gP3ToUFsEfy2HP6dPn5ZnnnlGokUDw9y5czPtf/fdd6NSntxGg7/+bu0U/CdOnChXX321/Pjjj/LQQw+Z7/rtt98u8+fPl3r16sk333wTcvDXz5qTwT+rvxsgkgj+uci2bdvMP2Ljxo2TSy+91NwI5Eb58uWTPHnyRO39/9//+39+g/+cOXOkQ4cOUSkTwqvxP/LII9KyZUv54YcfzI3lfffdJ2PGjJG1a9ea75veCBw5ciTaRQXsQ1f1Q+4wbNgwq1ixYtbZs2etBx980KpevbrP86+//rqu0JhpW7ZsmXXZZZdl2t+qVSvPa48cOWL17dvXKl++vJWYmGhVrVrVev7556309HTPMdu2bTOve+GFF6yXX37ZqlKlijm2cePG1urVqz3Hde/e3W853PTnwYMH+5R93bp11o033mgVLlzYKliwoHX99ddbK1eu9Pv5VqxYYT366KNWiRIlrAIFClidOnWy9u/ff9Hrp++pr3/77bfNfzdu3Oh5bs+ePVZCQoL1zjvvmOd69+7teU6v98CBA60rr7zSSk5ONu/ZsmVL6/PPP/c5v/f1GTdunFWxYkUrX7581jXXXGP9+OOPPsempaWZ99+9e3fA5T5w4IBnn/7uateubf3888/Wtddea+XPn98qW7asNWrUKJ/X6u9eXztv3jxrwIABVqlSpUz5b775Zmvnzp0+x+p3RH93Gel7ub8r7vNl3PR3489bb71lnl++fHmm56ZOnWqec18b/R3cc889Vrly5cz3qnTp0tYtt9xiruuFtGvXzvzufv/9d7/Pz5w507zPyJEj/X4mb/r59Tp4/z4zbu7vrh6r39WtW7dabdu2Nde1TJky1tChQy2Xy+U5p/ua6X+9uc/vvnYX+7sBIil61S8ETWv6t912myQmJkrXrl1lypQpsmbNGmnSpIl5/pprrpGHH35YJkyYIE899ZTUrFnT7Nf/jh8/3qRDCxUqJE8//bTZr22j7tRmq1at5I8//jBtpBUrVjQZhgEDBsiePXvMazPWkI8fP26O1bbo0aNHm3L9/vvvkjdvXrNfU8NLliyRN95446Kf6+effzYp2+TkZOnfv785x8svvyzXXnutfPHFF5n6N+jnKFasmAwePNg0b2j5tI1eU7yB0OtUvnx58zmeffZZs09fq9fGX81f+wK8+uqr5pr37NnTfPbXXntN2rVrZ5pfGjRo4HP8rFmzzDG9e/eWM2fOyEsvvSTXX3+9SUm7r7lea/29dO/ePeSmGK3J3njjjeba33nnnfL222/LE088IXXr1pX27dv7HDt8+HDzu9Ln9+/fb65ZmzZtTOpe+zkESsus12zQoEHyr3/9y/ze1FVXXeX3eL2eel0XLFhgvmPe9JrXrl1b6tSpYx537tzZfBf096tNW1pO/Q5pm70+9ke/u0uXLjXlqFy5st9junTpYsr64YcfypNPPhnwZ9Xsmv6NPfjgg6YvgV5npc0Ibunp6eZ38Le//c38HSxatMh8L8+fP+/5bgUq2L8bICwRvZVAtvnuu+9MLWDJkiXmsdYstJautXV/Na2MtQylNUV/tR3NKGgNZvPmzT77n3zySVOjctcQ3TWVSy65xDp8+LDnuPfff9/s/+9//+vZpzXnrL5eGWv+WnPXmp7WoNy0RqxZAK01Z6z5t2nTxqdmpVkALefRo0etQGvQjz32mFWtWjXPc02aNLF69OjhKZ93zf/8+fOm9u9NMyVai7733ns9+9zXR2vhu3bt8uz/9ttvzX4tZ8Zj/dW0L1RuN/096r5Zs2Z59mkZtbbcuXPnTLVOrU2npqZ69i9YsMDsf+mll4Kq+as1a9ZcsLafUdeuXa2SJUua6+imtfz4+Hjr2Wef9VxPd9YkGOvXrzevy/h3kFG9evWs4sWLZ/mZ/NX8lV5zf5kq97H63EMPPeTZp9/LDh06mO+z+/cVaM3/Yn83QCTR5p+Lav1aa7zuuuvMY63FaY1m3rx5pvYRjrfeesvUnLQ2rT3K3ZvWDPXcX375pc/x+r56rJu79qc1/2Dp+T/99FPp1KmTVKlSxbO/TJky8ve//11WrFhhat7etBann9/7/fU8O3bsCPh99dzaYVIzJ+7/6j5/EhISTLZFuVwuOXz4sKnZNW7cWNatW5fpeP0s5cqV8zxu2rSpyV5oZy43rcnqfUY4HTC1Rv2Pf/zD81jLqO/l7/fQrVs3KVy4sOextoHrNfYuU3bR74vW4r07zWmWQq+lPqc0+6Dl12OCaZvXDIvy/mz+6PMZv0eR4j0yxD1SJC0tTT777LNseT8gEgj+uYAGNg3yGvi1058GK900oOzbt8+kPcPx22+/mXSlpjm9Nw3+Sv/h9qbNAt7cNwKhdKg6cOCASd1eccUVflPMGiAyDsuLxPs3bNhQatSoYVL/emNVunRpk5rPysyZM026VzuPXXLJJeb6fPTRR3Ls2LFMx1avXj3Tvssvv9zvCIxwaNOF902Q+1r4uw4Zy6Svq1atWsTL5I+mxYsUKeLTLKM/a3OJXhf3CIxRo0bJJ598Ym5ytWlG0+h79+694LndQd99E5AVff5iNwih0GGj3jetyv2ZcuLaAqGizT8X+Pzzz03bu94A6JaRBq+2bduGfH4NsDfccINpb/fH/Y+Zd03Ynz8z5tkvUu+vNX1t09WgoDVQ/Yfcn9mzZ8s999xjavSPP/64lCxZ0pRh5MiRsnXrVomWSP8eMt5IeN98ZvVegdDArtfuvffeM0Pw9IZVe+iPGDHC5zjtsX/zzTfLwoULZfHixTJw4EBzjfX7rzdr/ugNjI4c0V7+WTl79qxs2rTJZGq8P6u/6xRuFi3Y6wpEC8E/F9DgrgFn8uTJfsem6z+qU6dO9UxQk5WsnqtataqcOHHCU9OPhAuVw5vWoAsUKGD+cc7o119/NQG5QoUKkh00+GvHNb2xulAHK01Ra+1Or7X359KOXVllUjLavHlzlp3WckLGMmng0+yRd+c1zRocPXo002u1OcW7dhvo79ab3lxp9kSzVBs3bjTv7075Z/wu/vvf/zabllmzA2PHjjU3YP4ULFjQZMT0BkHLedlll2U6Rjsb6g3ATTfd5PNZ/TWPZGw6uthn1RtnPY/3DbL+rpX79+3OTGW8tv6aqUK5tkAoSPvbnE6Io0FH/+HSdtqMm7Yvakrzgw8+8PxjqPz9I67P+duvPcVXrlxpalsZ6fHavh2sC5XDm9YoNWvx/vvv+6RJtXaoKXkdu62jALKDBhrt9a61S20rv1AZlXdN8dtvvzXXzB+tuWpvfjcdEaDHe/fAP3funLm50RuPnOAegeB9Q6Pv7V0mvR6rVq0y7dVu2kM+Y7NLoL9bb3pjWbx4cZPu102vt3fvfG360ZER3rQ8mpXRwH0hOq5ffzeandG/F2/aTKYZLe3foL3pvc+t11+bndw2bNhgMhLe9Mb0Yp910qRJnp+1HPpYR6y0bt3a7NMbEv0OZew7o1mQjEK5tkAoqPnbnAZ1/Uf7lltu8fu8DjFyT/ijNSmtKek/NNp+qu3RmnLVtmzNHDRq1MikuZ977jmTLtV9+pymsvV99AZD/wHV406ePGmGpmmQ0KBcokSJoMqt51A69FCHxGmZ7rrrLr/Hanl0eJMG+l69epk0rg7103/0td03O/Xt2/eix+h10RswHe6lQ9c0oGimpVatWiZjkpFeW/0sOkRMP4PeYGg/Ae9mlUgM9QuGBl4tU48ePcyNlZZJy6lDF93+7//+z/y+tY1ebwi1SUNr3BoovenjokWLmmugwVkDlvY/yWqondJgqEPltNlKv1s6AY83rS1rsNT31euq3wHNaGlZs/reuGn/AD1fv379TCZDv8Ma7DW4T5s2zdTOtWOjdyfVe++910yWpd9NnRBI+7Xo59Ghh94dAzWbpuXRGxat3et11KGJ7uGJ2gdE+8vo71GvgfZZ0L4gOtRW/y6V9ne44447zCyEWrPX66c3VRn70gT7dwOEJaJjBxBxOhmLThRz8uTJLI/RiVHy5s1rHTx40DyeNm2amYBHh795DzHau3evGYakQ+gyTvJz/PhxMwmMDn/TYUo6gc5VV11ljRkzxkxIk3ESm4wyDofSYV06BOrSSy+14uLiAprkRydrKVSokJks5brrrrO++eYbn2PcQ/10qJm3rIZSBTJkzp+MQ/10+NaIESPMELCkpCSrYcOG1ocffphpWJj39Rk7dqxVoUIFc/zVV19tbdiwwec9IjHUT4duZpSxTO5rM3fuXPP71SF3OhRRvwc7duzI9Hottw4L1HK3aNHCDDH1NyxOh3fWqlXLypMnT8DD/nSYqh6r34eUlBSf5/S7q9e8Ro0aZthpkSJFrGbNmpkhiYH68ssvrY4dO5rvrv496CRLPXv2tLZv3+73+NmzZ3smqmrQoIG1ePHiTNdP6fewUaNG5riLTfKjwz/1ee/JsZT+7nQIph6jE3Xdf//91k8//ZTp2l3o7waIpDj9v/BuHwAozZBo7feFF16Qxx57TOxAh85pm7gO59RmIkSOZhg0U+Iv+wPYHW3+AAA4DMEfAACHIfgDAOAwtPkDAOAw1PwBAHAYgj8AAA6Tqyf50ck7dP1rnWiEaTEBIPfRlmedyKxs2bJZrq8RCTqDpPfslaHS1Sd1cqdcz8rFdKIQ/QhsbGxsbLl7yzjxUySdPn3aKl3yz0nPwt1Kly5tzheMSZMmeSYJa9q0qfXtt99meew777xjJpXSia50Uqj69etbs2bN8jlGJ5jKWC6dJC0Yubrm716is8pDgyQhyT53Ysk7XWI3yVtsOBGJDbM18dtyZq79YMTlSxK7OVm7rNiNmQ/PZs4WCX01xOxy5JaTYieu02dl+wPjsmXJZTet8e/dny471laS5MKhZxdSj7vkskbbzfkCrf3r1NA69bROH61TQOvU2jp1sy5mplOsZ6RTSD/99NNmyXHNMuhU0Dottx6rr3PTabhff/11z2Odyj0YuTr4u1P9GvjtFPwT8tov+OdJCH5xHkcG//hEsZu4ePsF/zx57fP3Zufgn57XfsE/oYA9lxLOiabbQoXjzBYqlwT/Wl1DQtfQ0ACu9CZA13+YPn26PPnkk5mOv/baazOtP6IrYq5YscIn+GuwL126tISKDn8AAEdIt1xhb8HQDMHatWt9lkvXfg36OKtVQTP2h9BlsDVLoAtYZZy6W7MBV1xxhVlE7NChQ86p+QMAECiXWGYLlfu13is/umvh/tLuBw8elPT0dClVqpTPfn2sq05mRVdkLVeunFkVVFd21OWfb7jhBp+Uv66SqWuJ6OqbuoqkLs+tNxTuJcgvhuAPAEAQKlSo4PN48ODBMmTIEIkU7f+wfv16s2iU1vy1z0CVKlU8TQLeyzzXrVvXLGWtS0VrNkCXxg4EwR8A4Agu87/wXq9SUlIkOTn5op3tSpQoYWri+/bt89mvjy/UXq9NA9WqVTM/N2jQQDZu3CgjR47M1B/ATW8M9L22bNkScPCnzR8A4AjplhX2pjTwe29ZBX/trd+oUSNTe/een0YfN2/eXAKlr9EmgKzs2rXLtPmXKVMm4HNS8wcAIJtoyr579+7SuHFjadq0qRnqd/LkSU/v/27dupn2fa3ZK/2vHqtpfA34H3/8sbzxxhsyZcoU87w2BQwdOlQ6d+5ssgfa5t+/f3+TKfAeDXAxBH8AgCNEqsNfMLp06SIHDhyQQYMGyd69e00af9GiRZ5OgDt37vSZ2VBvDHr16mVq8/nz5zfj/WfPnm3Oo7QZ4YcffjDD/44ePWpmRmzbtq0MGzYsqLH+uXpVP+1xWaRIEan+2AhbjfNP3m6/cf5FNjPJTyDif/9D7CbOhlOJnqxXTuzGjuP87TjJz+HO9prkJ/3UGfm9+0jTw927HT07YsW2X8tI4TAm+Tl+3CWVa+zJ1rLmFNr8AQBwGNL+AABHiEba364I/gAAR/DusR+KcF5rN7ZI+0+ePFkqVapkFkrQhQ9Wr14d7SIBABCzoh783Sse6QxJ69atk/r165vhCvv374920QAAMcQVgS1WRD34e694VKtWLbPiUYECBcyKRwAAREq6WGFvsSKqwT/cFY8AAAhUuhX+Fiui2uEv2BWPdLYj7ykOM66sBAAAckHaPxg67aFO1ODeMq6sBABAVmjzt0nwD3bFowEDBpiZldybrqwEAEAgXBIn6WFsLrHfrKS5MvgHu+KRzluccTUlAACQyyb5udiKRwAARILL+nMLVTivtZuoB/+LrXgEAEAkuNP3oQrntXYT9eCv+vTpYzYAAOCQ4A8AQHaj5v8Xgj8AwBFcVpzZQhXOa+0mV43zBwAA4aPmDwBwBNL+fyH4AwAcIV3izRaqdIkdBH8AgCNYYbb5W7T5AwCA3IqaPwDAEWjz/wvBHwDgCOlWvNlClR5D0/uS9gcAwGGo+QMAHEGX5HWFUed1SexU/Qn+AABHoM0/xoJ/YqpIQqLYRoF958Ru4k/br0yy/7DYTVyijb5Ibol5xW5OlbLfPx3pNvzVpSfZL1icTU0SO3Gdjp3adG5iv79gAABs2eHPklhB8AcAOKjNP4yFfWIo7U9vfwAAHIaaPwDAEVxhzu3vorc/AAC5C23+fyH4AwAcU/NnnP+faPMHAMBhqPkDABwh3YozW6jCea3dEPwBAI6QHmaHv3TS/gAAILei5g8AcASXFW+2ULno7Q8AQO5C2v8vpP0BAHAYav4AAEdwhdlj3yWxg+APAHCE8Cf5iZdYETufBAAABISaPwDAEcKf2z9eYkXsfBIAAC7AJXFhb6GYPHmyVKpUSfLlyyfNmjWT1atXZ3nsu+++K40bN5aiRYtKwYIFpUGDBvLGG2/4HGNZlgwaNEjKlCkj+fPnlzZt2shvv/0WVJkI/gAAR9X808PYgjV//nzp16+fDB48WNatWyf169eXdu3ayf79+/0eX7x4cXn66adl5cqV8sMPP0iPHj3MtnjxYs8xo0ePlgkTJsjUqVPl22+/NTcJes4zZ84EXC6CPwAA2WTcuHHSs2dPE8Br1aplAnaBAgVk+vTpfo+/9tpr5dZbb5WaNWtK1apVpW/fvlKvXj1ZsWKFp9Y/fvx4eeaZZ6Rjx47muVmzZsnu3btl4cKFAZeL4A8AcNQkP+lhbCo1NdVnO3v2rN/3S0tLk7Vr15q0vFt8fLx5rDX7i9FAv3TpUtm0aZNcc801Zt+2bdtk7969PucsUqSIaU4I5JyecgR8JAAAuZjLigt7UxUqVDAB172NHDlS/Dl48KCkp6dLqVKlfPbrYw3gWTl27JgUKlRIEhMTpUOHDjJx4kS54YYbzHPu1wV7zozo7Q8AQBBSUlIkOTnZ8zgpKUkiqXDhwrJ+/Xo5ceKEqflrn4EqVaqYJoFIIfgDABzBFebc/q7/vVYDv3fwz0qJEiUkISFB9u3b57NfH5cuXTrL12nTQLVq1czP2tt/48aNJrugwd/9Oj2H9vb3PqceGyjS/gAAR63q5wpjC4am7Rs1amRq754yuFzmcfPmzQMvt8vl6VdQuXJlcwPgfU7td6C9/oM5JzV/AACyiabsu3fvbsbuN23a1PTUP3nypOn9r7p16yblypXz9BvQ/+qx2tNfA/7HH39sxvlPmTLFPB8XFyePPPKIPPfcc1K9enVzMzBw4EApW7asdOrUKeByEfwBAI6QLnFmC1Uor+3SpYscOHDATMqjHfI0Nb9o0SJPh72dO3eaNL+b3hj06tVLdu3aZSbwqVGjhsyePducx61///7muH/9619y9OhRadmypTmnTiIUqDhLxxLkUprq0J6Wtf81QhISA//Q2a34r/6HfURT0t4TYjv7D4vdxOVJENvJF9nORJFwoFVZsZv0RLGd9KTQA012OVY/TezEdfqM7OozxPRwD6QdPZxYMfTbNpKvUOh13jMnzsvgZp9la1lzCm3+AAA4DGl/AIAjpIeYuvd+fawg+AMAHCGUHvvewnmt3RD8AQCOwJK+f4mdTwIAAAJCzR8A4AiWxIkrjDZ/K4zX2g3BHwDgCKT9/xI7nwQAADin5n/p9yckT57zYhfxp8+J3cQds98kP1bxImI36YXtM1mU24lKBcVuzhaxX/rzXGGxnYQzYjvJP9lrNqT0s64cey/vZXlDEc5r7SYmgj8AABeTHuaqfukxlCyPnU8CAAACQs0fAOAIpP3/QvAHADiCS+LNFqpwXms3sfNJAABAQKj5AwAcId2KM1uownmt3RD8AQCOQJv/Xwj+AABHsMJc1c9ihj8AAJBbUfMHADhCusSZLVThvNZuCP4AAEdwWeG127ssiRmk/QEAcBhq/gAAR3CF2eHPRYe/yBg5cqQ0adJEChcuLCVLlpROnTrJpk2bolkkAECMcklc2FusiGrw/+KLL6R3796yatUqWbJkiZw7d07atm0rJ0+ejGaxAACIaVFN+y9atMjn8YwZM0wGYO3atXLNNddErVwAgNjDDH82bfM/duyY+W/x4sWjXRQAQIyhzd+Gwd/lcskjjzwiLVq0kDp16vg95uzZs2ZzS01NzcESAgAQG2xzG6Nt/z/99JPMmzfvgh0EixQp4tkqVKiQo2UEAOReptOeFcZGh7/I6tOnj3z44YeybNkyKV++fJbHDRgwwDQNuLeUlJQcLScAIPeywuzpb8VQ8A8p7a+98vfu3SunTp2SSy+9NOQ2esuy5KGHHpL33ntPli9fLpUrV77g8UlJSWYDACBYrOoXQs3/+PHjMmXKFGnVqpUkJydLpUqVpGbNmib4X3bZZdKzZ09Zs2aNBENT/bNnz5Y5c+aYsf56Q6Hb6dOngzoPAACIcPAfN26cCfavv/66tGnTRhYuXCjr16+XzZs3y8qVK2Xw4MFy/vx5M0b/xhtvlN9++y2gN9ebCU3fX3vttVKmTBnPNn/+/CA+AgAAgff2d4WxOSrtrzX6L7/8UmrXru33+aZNm8q9994rU6dONTcIX331lVSvXj2gtD8AADmBtH+QwX/u3LmBHGba4x944IGAjgUAANERdg5Dx9prM8DGjRsjUyIAALIBc/uHEfzvvPNOmTRpkvlZO+Y1btzY7KtXr5688847wZ4OAIAcEdYYfyu8JoNcH/y17f/qq682P+sQPW23P3r0qEyYMEGee+657CgjAACIZvDX3vnucf26ME/nzp2lQIEC0qFDh4B7+QMAkNOo+YcR/HVKXR3ep8vuavDX4X3qyJEjki9fvmBPBwBAjiD4hzHDny6+c/fdd0uhQoWkYsWKZoy+uzmgbt26wZ4OAADYPfj36tXLjOvXefVvuOEGiY//M3lQpUoV2vwBALbFOP8w5/bXHv7au3/btm1StWpVyZMnj2nzBwDArnRauXCG61kizm3z18V87rvvPtPJT2f827lzp9mvC/Q8//zz2VFGAADCRpt/GMFfl9XdsGGDWYXPu4OfzvnPnPwAAMRg8NfZ/HSSn5YtW0pc3F93QZoF2Lp1a6TLBwBArq75T5482SyOpxXmZs2ayerVq7M8dtq0aWYunWLFiplNK9YZj7/nnntM/PXedFG9bG3zP3DggJQsWTLTfh36530zkJPif90h8XGJYheWDZckdiUlie1ckix248qbIHaTft9BsZvjW0uI3Vh57NciW/ntdLGbxCNnxE7Op5+VjTHc4W/+/PnSr18/s/CdBv7x48dLu3btZNOmTX5jqWbVu3btKldddZW5WRg1apQZUv/zzz9LuXLlPMdpsNeF9LzX1snWmr929vvoo488j90B/9VXX5XmzZsHezoAAGLWuHHjpGfPntKjRw+pVauWuQnQPnPTp0/3e/ybb75pRtU1aNBAatSoYWKry+WSpUuX+hynwb506dKeTbME2VrzHzFihLRv315++eUXOX/+vLz00kvm52+++Ua++OKLYE8HAECuqvmnpqZmCsT+at5paWmydu1a01fOTYfHaypfJ8sLtJP9uXPnPDPremcINHOgQf/66683Q+0vueSS7Kv5a1v/+vXrTeDXSX0+/fRTUwD9II0aNQr2dAAA5AjLigt7c890W6RIEc82cuRI8efgwYOSnp4upUqV8tmvj/fu3SuBeOKJJ6Rs2bLmhsE75T9r1iyTDdBmAa14a6Vc3ytbx/nr2H7tlAAAgNOkpKRIcnJyyO3tgdLh8/Pmzcs0uu6uu+7y/KyVcJ13R+OyHte6devIBX9Ncbg/aMZ0R0beFwQAALvQCX7CmeTH9b/XapwLJNaVKFFCEhISZN++fT779bG201/ImDFjTPD/7LPPTHC/EJ1hV99ry5YtAQf/gNL+2qawf/9+83PRokU9QxC8N/d+AADsKKeH+iUmJprmcO/Oeu7OexfqID969GgZNmyYWTxPO9lfzK5du+TQoUNSpkyZgMsWUM3/888/93Q2WLZsWcAnBwDAyfr16yfdu3c3QVzXxdGhfjo0Xnv/q27dupkhfO5+A9qGP2jQIJkzZ46ZG8DdN0AX09PtxIkTMnToUOncubPJHuj8Ov3795dq1aqZIYQRDf6tWrUy/9VOftqx4N5775Xy5cuHch0AAIgK7057oQjltV26dDHz42hA10CuQ/i0Ru/uBKhT5LsXyFNTpkwxowRuv/12n/MMHjxYhgwZYpoRfvjhB5k5c6YcPXrUdAbUeQA0UxBM34OgOvzpAj4vvPCCuVMBACA3idaqfn369DGbP9pJz9v27dsveK78+fPL4sWLJVxBD/XT8YSM5wcAOHWoXywIeqifjiV88skn5ccffzQdGQoWLOjz/C233BLJ8gEAgGgHf5120D1lYUY61W8wkwwAAJBTrDDT/paTa/46TAEAgNxGl36ywlj/yZLYEXSbv7czZ+y1OhQAAMiG4K9pfR1SoOMSdczh77//bvYPHDhQXnvttWBPBwBAjs7w5wpjc2zwHz58uMyYMcPMQKSzF7nVqVPHLD0IAIAd0ds/jOCvKwm98sorcvfdd5vJBtzq168vv/76a7CnAwAAdu/w98cff5hpBP11BNQ1hwEAsCPt6R8XhUl+YqLmX6tWLfnqq68y7X/77belYcOGkSoXAAARpT39w90cW/PX+Yl1kQLNAGht/91335VNmzaZ5oAPP/wwe0oJAACiV/Pv2LGj/Pe//zVrDOvsfnozsHHjRrPvhhtuiFzJAACIIDr8hVHzV1dffbUsWbIklJcCAOCYVf1iKvgDAJDb0OEvjOCv6w7rHP5ZYW5/AABiLPi/9957Po91eN/3338vM2fOlKFDh0aybAAAREy4PfYtJ/f21w5/Gd1+++1Su3ZtmT9/vtx3332RKhsAABEO/uG0+UvMCGthH29/+9vfZOnSpZE6HQAAsHOHv9OnT8uECRPMYj8AANgRvf3DCP7FihXz6fBnWZYcP35cChQoILNnzw72dAAA5AjN2oeTubdEnBv8X3zxRZ/gr73/L730UmnWrJm5MQAAADEW/O+5557sKQkAANmItH8YwX/NmjUyd+5c2bx5syQmJsoVV1wh3bp1k5o1awZ7KgAAcg55/9B6+/fv39+k91999VXZtWuX/P777zJp0iSpW7eujBo1yhxz5swZWbZsWTCnBQAg+4U7r78V57zgr5P4TJw40fTqP3TokKxfv95shw8flnHjxpkJfhYsWCDt27eXr7/+OntLDQAAsj/tP3nyZBkxYoT06dPHZ3/evHnl4YcflvPnz0vXrl2lQYMG0rt379BLBABANmCGvxBq/j///LPf2f3cOnXqZIb96UQ/9PoHANgNS/qGUPNPSEiQtLS0LJ/XOf4LFSokRYsWlZzmOn5CXHF5xS7i8thwsUQb3rKmlSggdvP7HQliN6Wsk2I3Vrz9vk/F19nvd5dv/VaxnWJFxE7i089GuwiOFHDN/8orr5Q333wzy+ffeOMNcwwAALbk7rRnhbHFiICrqI899phJ7Z89e1b+/e9/S6lSpcz+vXv3ytixY2X8+PHy7rvvZmdZAQAIGW3+IQT/m266yczupzcBGuyLFPkzdXTs2DHTJPDCCy/IzTffHOjpAABAlATVOP3QQw/JrbfeKm+99Zb89ttvZl/16tXNkr4VKlTIrjICABA+JvnxCLpnWvny5eXRRx8N9mUAAEQV0/sG2eFv1apVEqhTp06ZYYEAACAXB/9//vOf0q5dO5PuP3nS/7CjX375RZ566impWrWqrF27NtLlBAAgcql/K4RNHJb218A+ZcoUeeaZZ+Tvf/+7XH755VK2bFnJly+fHDlyRH799Vc5ceKE6Q/w6aefmrn+AQCwE9L+QQZ/9xS+un333XeyYsUK2bFjh5w+fVrq169v+gBcd911Urx48UBOBwBAzqPDX+gd/ho3bmw2AACQO9lwHloAALKDpu3DSd07LO0PAECuR9o/+Ln9AQBAbLBN8H/++eclLi5OHnnkkWgXBQAQi8IZ5mdR88/k6NGjYb1+zZo18vLLL0u9evUiURwAADJjVb/Qg/+oUaNk/vz5nsd33nmnXHLJJVKuXDnZsGFDsKcz8wPcfffdMm3aNClWrFjQrwcAwM4mT54slSpVMnPjNGvWTFavXp3lsRoLr776ahMPdWvTpk2m4y3LkkGDBkmZMmUkf/785hj3ejvZFvynTp3qWcRnyZIlZvvkk0+kffv28vjjjwd7Oundu7d06NDBFP5idDnh1NRUnw0AgGCW9LXC2IKlleV+/frJ4MGDZd26dWZuHJ0xd//+/X6PX758uXTt2lWWLVsmK1euNPG2bdu28scff3iOGT16tEyYMMHE42+//VYKFixoznnmzJnsC/579+71BP8PP/zQ1Py1YP379zfp+2DMmzfPXIyRI0cGdLwep0sJuzdWEgQA2LnNf9y4cdKzZ0/p0aOH1KpVywTsAgUKyPTp0/0e/+abb0qvXr2kQYMGUqNGDXn11VfF5XLJ0qVL//wIliXjx483M+527NjRNJfPmjVLdu/eLQsXLsy+4K9piJSUFPPzokWLPDV2LVB6enrA59Fz9O3b13xQTYUEYsCAAXLs2DHP5i4HAAB2k5aWZta68c5sx8fHm8daqw90sbxz5855ZtDdtm2bqYR7n1Mrw9qcEOg5Qxrnf9ttt5n5/atXry6HDh0y6X71/fffS7Vq1QI+j14QTXtceeWVnn168/Dll1/KpEmTTIo/ISHB5zVJSUlmAwAgaOF22rP+fG3GJuesYtPBgwdNXCtVqpTPfn2sa+IE4oknnjBr6biDvQZ+9zkyntP9XLYE/xdffNF0XNBat7Y7FCpUyOzfs2ePSVUEqnXr1vLjjz/67NO0iKY59MNmDPwAAIQjzvpzC5X7tRmbnLU9f8iQIZIdQ+C1eVz7AQSaIc+24K+L/Dz22GOZ9uviPsEoXLiw1KlTx2efdlrQkQMZ9wMAYJcZ/lJSUiQ5OdmzO6uMdIkSJUxFdt++fT779XHp0qUv+FZjxowxwf+zzz7zGQbvfp2eQ3v7e59T+wlk6/S+OqRAeyJq2l47InjT4QcAAMSq5ORkn+CflcTERGnUqJHprNepUyezz915r0+fPlm+TrPqw4cPl8WLF2daSK9y5crmBkDP4Q722gyhvf4ffPDB7Av+OgZR30DvaLQAOiufm/4cTvDX1AYAAHZu8w+GDvPr3r27CeJNmzY1PfVPnjxpmrlVt27dzDw57lFvOpeOxtE5c+aYJnZ3O742sevmngn3ueeeM33v9GZg4MCBpl+A+wYjW4K/vqHekWi7PAAAuUYUFvbp0qWLHDhwwAR0DeRaW9eRcu4Oezt37jQjANymTJliRgncfvvtWfYr0KH1egPxr3/9y8yw27JlS3POYPoFBB38jxw5InfccUewLwMAwJH69OmTZZo/Y8Z7+/btFz2f1v6fffZZs4Uq6HH+Gvg//fTTkN8QAICoYGGf0Gv+OpZf2xdWrVoldevWNb3/vT388MPBnhIAgJhM+8dM8H/llVdMp4MvvvjCbBlTEQR/AABiLPjr1IIAAOQ6Uejtb1chjfN30/n8lfdwPwAAYnmGv1gQdIc/pSsIaXu/riOsm84+9MYbb0S+dAAAIPo1f12eUDv86bCFFi1amH0rVqyQBx54wCxiEOw0vwAA5Ag6/IUe/CdOnGgmIdBZidxuueUWqV27tpmAgOAPAECMBX9dve+qq67KtF/36XMAANiR9k4Lq81fHNzmr+P8FyxYkGn//PnzzTzDAAAgxmr+Q4cONXMVf/nll542/6+//tqsMOTvpiAnJFS5TBIS/C+pGA3nyhUVu0mtGNm1oCPhfH6xnSZ1Novd/PLhFWI3VVedEbvJezBV7MY6myZ2E3fkmNiKKwevEUP9Qg/+nTt3NksHvvjii7Jw4UKzr2bNmrJ69Wpp2LBhsKcDACBn0OEvvHH+uj7x7NmzQ3kpAADIDcE/NTVVkpOTPT9fiPs4AABshZp/cMG/WLFipid/yZIlpWjRon5n9NPZ/nR/enp6IKcEACBHMcNfkMH/888/l+LFi5ufly1bFshLAABAbg7+rVq18vxcuXJlqVChQqbav9b8U1JSIl9CAAAigbR/6OP8NfgfOHAg0/7Dhw+b5wAAsHXwt8LYnBr83W37GZ04cULy5bPfWHIAABDiUL9+/fqZ/2rg14V9ChQo4HlOO/np2P8GDRoEejoAAHIUHf5CCP7ff/+9p+b/448/SmJiouc5/bl+/fry2GOPBXo6AAByFjP8BR/83b38e/ToIS+99BLj+QEAuQsd/kKf4e/1118P9iUAACC3Bf/bbrtNZsyYYWr7+vOFvPvuu5EqGwAAEUObf5DBv0iRIp4e/vozAAC5Dmn/4IK/d6qftD8AAA4b53/69Gk5deqU5/GOHTtk/Pjx8umnn0a6bAAARM7/0v5xIW6xVPMPOvh37NhRZs2aZX4+evSoNG3aVMaOHWv2T5kyJTvKCABA+JjhL/Tgv27dOrn66qvNz2+//baULl3a1P71hmDChAnBng4AANh9qJ+m/AsXLmx+1lS/9v6Pj4+Xv/3tb+YmAAAAW6LDX+g1/2rVqsnChQvNCn6LFy+Wtm3bmv379+9n4h8AgG2F094fF+YwwVwf/AcNGmSm8a1UqZJp72/evLknC9CwYcPsKCMAAIhm2v/222+Xli1byp49e8x8/m6tW7eWW2+9NZJlAwAAdgj+Sjv56bZr1y7zuHz58iYLAACAbdHmH3ra3+VyybPPPmtm+rvsssvMVrRoURk2bJh5DgAAO6LNP4ya/9NPPy2vvfaaPP/889KiRQuzb8WKFTJkyBA5c+aMDB8+PNhTAgAAOwf/mTNnyquvviq33HKLZ1+9evWkXLly0qtXL4I/AMC+Yqj2nqPB//Dhw1KjRo1M+3WfPgcAgC3R5h96m7/28J80aVKm/brPu/c/AACIkZr/6NGjpUOHDvLZZ595xvivXLnSTPrz8ccfZ0cZAQAIW7id9uKcXPNv1aqVbN682Uzrqwv76KY/b9q0yTPnPwAAtsPCPqHV/Ldv3y5LliyRtLQ0ueuuu6ROnTrBvBwAAOSm4L9s2TK56aab5PTp03++ME8emT59uvzjH//IzvIBABARpP1DSPsPHDhQbrjhBvnjjz/k0KFD0rNnT+nfv3+gLwcAILpI+wcf/H/66ScZMWKElClTRooVKyYvvPCCWclPbwQAAIB/kydPNovh5cuXT5o1ayarV6/O4kiRn3/+WTp37myOj4uLk/Hjx2c6RifV0+e8N39D8CMS/FNTU6VEiRKexwUKFJD8+fPLsWPHgnpDAACcUvOfP3++9OvXTwYPHizr1q0zQ+LbtWtnKs/+nDp1SqpUqWJm0dU1dLJSu3Zts8Cee9OZdrOtw9/ixYvNnP5uOpf/0qVLTVbAzXvmPwAAnNzmP27cONNM3qNHD/N46tSp8tFHH5k+c08++WSm45s0aWI25e95N+13d6Gbg4gG/+7du2fad//993t+1tRDenq65LTUupdKnrz5xC7OFQx6BGW2O1RXbKfg7jixm+/WVxO7qbQuTewmcbcNM35HUsVurHPnxHbKhx4wskX6WZFDuWuGv9RU3+9aUlKS2TLSkXFr166VAQMGePbFx8dLmzZtzPw44fjtt9+kbNmypilB59wZOXKkVKxYMeDXBxyltJZ/sS0agR8AgJxUoUIFkwV3bxp4/Tl48KCJi6VKlfLZr4/37t0b8vtrv4EZM2bIokWLZMqUKbJt2zYzz87x48ezb4Y/AABypQjV/FNSUiQ5Odmz21+tPzu1b9/eZ2E9vRm47LLLZMGCBXLfffcFdA6CPwDAESLV5p+cnOwT/LOineQTEhJk3759Pvv1cTjt9RkVLVpULr/8ctmyZUvAr7Ff4zQAADEgMTFRGjVqZDrGZ+wo714bJxJOnDghW7duNUPxA0XNHwDgDFFY0rdfv36ms3zjxo2ladOmZtz+yZMnPb3/u3XrJuXKlfP0G9BOgr/88ovnZ51Yb/369VKoUCGpVu3PDsmPPfaY3HzzzSbVv3v3bjOMUDMMXbt2DbhcBH8AgCNEY6hfly5d5MCBAzJo0CDTya9Bgwamo567E+DOnTvNCAA3DeYNGzb0PB4zZozZdFG95cuXm327du0ygV4n2bv00kulZcuWsmrVKvNztgV/nXxgzZo1cskll/js19X9rrzySvn999+DPSUAADGrT58+ZvPHHdDddGY/y7rwXca8efPCLlPQwV9X9vM3pO/s2bMmPQEAgC1FIe1vVwEH/w8++CDLmf70ZkA7MOgdCwAAtkTwDz74d+rUyTOLX8aZ/vLmzWsC/9ixYwM9HQAAsHvw1+EJqnLlyqbN33uRHwAA7E4nFA9nUvE4iR1Bt/nrNIIAAOQ6pP1DD/7PPvvsBZ/X4QwAANhNNIb6xUzwf++993wenzt3zmQDdHnBqlWrBh38dYTAE088IZ988olZx1gnMXj99dfNhAgAAMAGwf/777/PtE+XN7znnnvk1ltvDepcR44ckRYtWsh1111ngr9OUKDLFBYrVizYYgEAcGGk/SM7w58ucDB06FAz3eA///nPgF83atQoszSi1vTdtEMhAADZIoYCeDgitrDPsWPHzBYMnTtA0/t33HGHlCxZ0kxpOG3atCyP14mENMvgvQEAgGyu+U+YMMHnsU5DuGfPHnnjjTd81hgOhE4FPGXKFLPwwVNPPWWGED788MNmJaSMcwkoXfhAMwwAAASLDn9hBP8XX3zR57EuSKBt9RqsBwwYENS5dO4ArfmPGDHCPNaa/08//SRTp071G/z1/Hqj4KY1f202AADgomjzt8c4f117uFatWj77atasKe+8847f45OSkswGAACi1OEvJSXF/DfU2rf29N+0aZPPvs2bN5s1igEAiCTS/mF0+Dt//rwMHDjQLOyj8/nrpj8/88wzZsx/MB599FGzBrGm/bds2SJz5syRV155RXr37h1ssQAACCztb4WxObXm/9BDD8m7774ro0ePlubNm5t9K1eulCFDhsihQ4dMB75ANWnSxEwapG35OnOgDvMbP3683H333cEWCwAAZFfw19r5vHnzfHr216tXz6T+u3btGlTwVzfddJPZAADITqT9wwj+2uFOU/0Zaa1dh+gBAGBL9PYPvc2/T58+MmzYMDPhjpv+PHz4cPMcAAC2RJt/eHP7L126VMqXLy/169c3+zZs2CBpaWnSunVrue222zzHat8AAACQy4N/0aJFpXPnzj77mGgHAGB3tPmHEfy9F+EBACDXoM0/9Db/66+/Xo4ePZppv061q88BAIAYq/kvX77ctO9ndObMGfnqq68iVS4AACIqzrLMFqpwXptrg/8PP/zg+fmXX36RvXv3eh6np6fLokWLpFy5cpEvIQAAkUDaP/jg36BBA4mLizObv/R+/vz5ZeLEiYGeDgAA2D3462p+lmVJlSpVZPXq1WYZXzed3KdkyZKSkJCQXeUEACAs9PYPIfi7V9pzuVyBvgQAAPsg7R96h79Zs2Zd8Plu3boFe0oAAGDn4N+3b1+fx7qM76lTp0zqv0CBAlEJ/scrJkhCkn2aHNKTxHYKVD8idnPuWDGxm6rz/pq22i4Sdx0W2zl3XuzGjpWyuCLJYjdWUl6xEys957LJpP3DGOd/5MgRn+3EiROyadMmadmypcydOzfY0wEAkDOY2z/04O9P9erV5fnnn8+UFQAAwC7cNf+4MLZYEZHgr/LkySO7d++O1OkAAIBd2vw/+OADn8c6/G/Pnj0yadIkadGiRSTLBgBA5NDbP/Tg36lTJ5/HOumPjvnXiX/Gjh0b7OkAAMgxsZS6z9Hgzzh/AAAcFvzdDh48aP5bokSJSJYHAIDsoQvzhLM4j2U5s8OfLuXbu3dvE/BLlSplNv25T58+fpf5BQDALujtH0LN//Dhw9K8eXP5448/5O6775aaNWt6VvibMWOGLF26VL755hspVsx+E7cAAIAQgv+zzz5rZvHbunWrqfFnfK5t27bmvy+++GKgpwQAIOfQ2z/4tP/ChQtlzJgxmQK/Kl26tIwePVree++9QE8HAECOinOFvzku+OtY/tq1a2f5fJ06dWTv3r2RKhcAAIh28NeOfdu3b8/y+W3btknx4sUjVS4AACKLuf2DD/7t2rWTp59+WtLS0jI9d/bsWRk4cKDceOONgZ4OAIAcRW//EIK/dubT1ft0ER9t39dpft9//32zoI/u27hxowwdOjTQ0wEAEJ1x/lYYWwgmT54slSpVknz58kmzZs1k9erVWR77888/S+fOnc3xOoPu+PHjwz5nWMG/fPnysnLlSqlVq5YMGDDATPN76623mmyA7vv666+lQoUKQb05AACxbP78+dKvXz8ZPHiwrFu3TurXr28y6fv37/d7/KlTp6RKlSqmYq2d6SNxzrAn+alcubJ88sknZna/VatWme3AgQOyaNEiqVatWjCnAgAg5tP+48aNk549e0qPHj1MRXnq1KlSoEABmT59ut/jmzRpIi+88ILcddddkpSUFJFzRmx6X53Ip2nTpqG8FACAXD3OPzU11We3Bml/gVr7yK1du9Zky93i4+OlTZs2JpMeikidM6iaPwAATlehQgUpUqSIZxs5cqTf4zRLnp6enml+HH0c6tD4SJ0z5IV9AADITcLtsR/3v9empKRIcnKyZ39W6Xk7I/gDAJwhQqv6JScn+wT/C82Pk5CQIPv27fPZr4+z6syXU+ck7Q8AQDbQ9XAaNWpkFr5zc7lc5rEulBfNc1LzBwA4QqTS/sHQIXndu3eXxo0bm47yOm7/5MmTpqe+6tatm5QrV87Tb0A79Olque6fdSXd9evXS6FChTyj6i52zkAQ/AEAzhCFVf26dOlihsQPGjTIdMhr0KCBGR7v7rC3c+dO01vfbffu3dKwYUPPY11QT7dWrVrJ8uXLAzpnIAj+AABkoz59+pjNH3dAd9NZ+6wA+iVc6JyBIPgDABwhGml/uyL4AwCcwWX9uYUqnNfaDMEfAOAMUWjztyuG+gEA4DDU/AEAjhAXZrt9nMQOgj8AwBkiNMNfLCDtDwCAw1DzBwA4AkP9/kLwBwA4A739PUj7AwDgMNT8AQCOEGdZZgtVOK+1m9gI/lcdFSmQJHZx6mBBsZuELUXEbiquThO7Sdy2X+wmfZ/9yhSXmCh2E1/qUrEdGwaLo1dcfB36nHT+3BmRH3LozVz/20IVzmtthrQ/AAAOExs1fwAALoK0/18I/gAAZ6C3vwfBHwDgDMzw50GbPwAADkPNHwDgCMzw9xeCPwDAGUj7e5D2BwDAYaj5AwAcIc715xaqcF5rNwR/AIAzkPb3IO0PAIDDUPMHADgDk/x4EPwBAI7A9L42Sfunp6fLwIEDpXLlypI/f36pWrWqDBs2TKwYusAAANhNVGv+o0aNkilTpsjMmTOldu3a8t1330mPHj2kSJEi8vDDD0ezaACAWEOHP3sE/2+++UY6duwoHTp0MI8rVaokc+fOldWrV0ezWACAWKSxO5zhepbEjKim/a+66ipZunSpbN682TzesGGDrFixQtq3b+/3+LNnz0pqaqrPBgBAMG3+cWFssSKqNf8nn3zSBPAaNWpIQkKC6QMwfPhwufvuu/0eP3LkSBk6dGiOlxMAgFgS1Zr/ggUL5M0335Q5c+bIunXrTNv/mDFjzH/9GTBggBw7dsyzpaSk5HiZAQC5eajf/9r9Q9okZkS15v/444+b2v9dd91lHtetW1d27Nhhavjdu3fPdHxSUpLZAAAIGh3+7FHzP3XqlMTH+xZB0/8uVwxNoAwAgM1EteZ/8803mzb+ihUrmqF+33//vYwbN07uvffeaBYLABCLtF4ZF+brY0RUg//EiRPNJD+9evWS/fv3S9myZeX++++XQYMGRbNYAIAYxAx/Ngn+hQsXlvHjx5sNAADkDOb2BwA4Ax3+PAj+AABnIPjbo7c/AADIedT8AQDOQM3fg+APAHAGhvp5EPwBAI7AUL+/0OYPAIDDEPwBAM4Q1qI+Vsht/pMnT5ZKlSpJvnz5pFmzZrJ69eoLHv/WW2+Z1W71eF3z5uOPP/Z5/p577pG4uDif7cYbbwyqTAR/AIAzuKzwtyDNnz9f+vXrJ4MHDzar19avX1/atWtnZrX155tvvpGuXbvKfffdZ6a879Spk9l++uknn+M02O/Zs8ezzZ07N6hyEfwBAMgmul5Nz549pUePHlKrVi2ZOnWqFChQQKZPn+73+JdeeskEdl31tmbNmjJs2DC58sorZdKkST7H6Qq3pUuX9mzFihULqlwEfwCAM+Rw2j8tLU3Wrl0rbdq08ezTlWz18cqVK/2+Rvd7H680U5Dx+OXLl0vJkiXliiuukAcffFAOHToUVNno7Q8AcIgwx/nLn69NTU3NVAvXLaODBw9Kenq6lCpVyme/Pv7111/9vsPevXv9Hq/73TQzcNttt0nlypVl69at8tRTT0n79u3NDUJCQoJzgv/KRm9LcmH7JDGufPZBsZukVPsNUcmXckxsJ94+3yO3+EIFxW7iihUVuzlZs6TYTfx5+/3dFftim9jJeVea5DYVKlTweazt+UOGDMmx97/rrrs8P2uHwHr16knVqlVNNqB169bOCf4AAOTUDH8pKSmSnJzs2e2v1q9KlChhauL79u3z2a+PtZ3eH90fzPGqSpUq5r22bNkScPC3XzUHAAAb9/ZPTk722bIK/omJidKoUSNZunTpX0Vwuczj5s2b+32N7vc+Xi1ZsiTL49WuXbtMm3+ZMmUCvhQEfwAAsokO85s2bZrMnDlTNm7caDrnnTx50vT+V926dZMBAwZ4ju/bt68sWrRIxo4da/oFaHPCd999J3369DHPnzhxwowEWLVqlWzfvt3cKHTs2FGqVatmOgYGirQ/AMAZLNefW6hCeG2XLl3kwIEDMmjQINNpr0GDBia4uzv17dy504wAcLvqqqtkzpw58swzz5iOfNWrV5eFCxdKnTp1zPPajPDDDz+Ym4mjR49K2bJlpW3btmZIYFYZCH8I/gAAZ4jSqn59+vTx1Nwz0k56Gd1xxx1m8yd//vyyePFiCRfBHwDgDKbNPozgH8IMf3ZFmz8AAA5DzR8A4AxRSvvbEcEfAOAMJusfTvCXmEHaHwAAh6HmDwBwBtL+HgR/AIAzuHScfhjj/M3rYwNpfwAAHIaaPwDAGUj7exD8AQDOQPD3IO0PAIDDUPMHADgD0/t6EPwBAI5gWS6zhSqc19oNwR8A4AzaZh9O7d2KnZo/bf4AADgMNX8AgDOYmjs1f0XwBwA4g87QFxdGu30MtfmT9gcAwGGo+QMAnIG0vwfBHwDgCJbLJVYYaX+LtD8AAMitqPkDAJyBtL8HwR8A4Aw6wU8cwV+R9gcAwGGo+QMAnMGk7cMZ50/aHwCAXMVyWWKFkfa3CP4AAOQyZqgeM/wp2vwBAHAYav4AAEcg7f8Xgj8AwBlI+8dG8HffhaWesNcvJD3tjNhN+jn73bGeTz8rdhPnsl+ZLCtN7MaO1+n8Ofv93cWn2/DvzpVmy/LkRK36vJwLa46f8/r6GBFn5eI8xq5du6RChQrRLgYAIEwpKSlSvnz5bDn3mTNnpHLlyrJ3796wz1W6dGnZtm2b5MuXT3KzXB38XS6X7N69WwoXLixxcXFhnSs1NdXcSOgXMDk5OWJljDVcp4vjGgWG6xSYWL9OGoKOHz8uZcuWlfj47OuDrjcAaWnhZz0SExNzfeDP9Wl//aJE+k5R/7hi8Q8s0rhOF8c1CgzXKTCxfJ2KFCmS7e+hATsWgnakMNQPAACHIfgDAOAwBP//SUpKksGDB5v/Imtcp4vjGgWG6xQYrhOyQ67u8AcAAIJHzR8AAIch+AMA4DAEfwAAHIbgDwCAwxD8RWTy5MlSqVIlMwFEs2bNZPXq1dEukq2MHDlSmjRpYmZSLFmypHTq1Ek2bdoU7WLZ3vPPP29mnnzkkUeiXRTb+eOPP+Qf//iHXHLJJZI/f36pW7eufPfdd9Eulq2kp6fLwIEDzbS0eo2qVq0qw4YNi6mV5RA9jg/+8+fPl379+pmhNOvWrZP69etLu3btZP/+/dEumm188cUX0rt3b1m1apUsWbJEzp07J23btpWTJ09Gu2i2tWbNGnn55ZelXr160S6K7Rw5ckRatGghefPmlU8++UR++eUXGTt2rBQrVizaRbOVUaNGyZQpU2TSpEmyceNG83j06NEyceLEaBcNMcDxQ/20pq+1Wv0Dc68XoPNoP/TQQ/Lkk09Gu3i2dODAAZMB0JuCa665JtrFsZ0TJ07IlVdeKf/5z3/kueeekwYNGsj48eOjXSzb0L+rr7/+Wr766qtoF8XWbrrpJilVqpS89tprnn2dO3c2WYDZs2dHtWzI/Rxd89dFHtauXStt2rTxWS9AH69cuTKqZbOzY8eOmf8WL1482kWxJc2SdOjQwed7hb988MEH0rhxY7njjjvMTWTDhg1l2rRp0S6W7Vx11VWydOlS2bx5s3m8YcMGWbFihbRv3z7aRUMMyNUL+4Tr4MGDpl1N76696eNff/01auWyM82MaBu2pm3r1KkT7eLYzrx580zzkab94d/vv/9u0tna3PbUU0+Za/Xwww+b1dK6d+8e7eLZKkOiK/rVqFFDEhISzL9Vw4cPl7vvvjvaRUMMcHTwR2i12p9++snUQOBLl1zt27ev6RfB6mEXvoHUmv+IESPMY63563dq6tSpBH8vCxYskDfffFPmzJkjtWvXlvXr15sbb136luuEcDk6+JcoUcLcUe/bt89nvz4uXbp01MplV3369JEPP/xQvvzyy4gvpRwLtAlJO4pqe7+b1tb0emmfkrNnz5rvm9OVKVNGatWq5bOvZs2a8s4770StTHb0+OOPm9r/XXfdZR7riIgdO3aY0TcEf4TL0W3+mmZs1KiRaVfzrpXo4+bNm0e1bHaifUI18L/33nvy+eefm6FHyKx169by448/mhqae9MarqZp9WcC/5+0ySjjUFFt177sssuiViY7OnXqlOmD5E2/Q/pvFBAuR9f8lbY76l20/iPdtGlT0ytbh7D16NEj2kWzVapfU4/vv/++Geu/d+9es79IkSKm5zH+pNcmYz+IggULmrHs9I/4y6OPPmo6s2na/8477zTzarzyyitmw19uvvlm08ZfsWJFk/b//vvvZdy4cXLvvfdGu2iIBTrUz+kmTpxoVaxY0UpMTLSaNm1qrVq1KtpFshX9mvjbXn/99WgXzfZatWpl9e3bN9rFsJ3//ve/Vp06daykpCSrRo0a1iuvvBLtItlOamqq+e7ov0358uWzqlSpYj399NPW2bNno100xADHj/MHAMBpHN3mDwCAExH8AQBwGII/AAAOQ/AHAMBhCP4AADgMwR8AAIch+AMA4DAEfyCK4uLiZOHChRc85p577pFOnTpJtOm01zoHv65XYAeLFi2SBg0aMN0tEAKCP6IqWoFtxowZUrRo0YCO0wCtm86zrgsa6dTPuoBPJOzZs8ezPvv27dvN++g6AN5eeuklU45o69+/vzzzzDOeNQr8XcONGzdKhQoV5I477pC0tLRsLc+NN94oefPmNSvfAQgOwR+4iOTkZBOkd+3aJdOmTZNPPvlE/vnPf0bk3Lp6ZFJS0gWP0TUUArlRyU66hPPWrVulc+fOWR6zZs0aufrqq01Qnj9/vlk4KyduHidMmJDt7wPEGoI/bOXaa6+Vhx9+2NQyixcvboLjkCFDfI7R2vGUKVNMjVkXFqpSpYq8/fbbnueXL19ujjl69Khnn9amdZ/WrvV5rb0fO3bMU6vP+B4Z30/Loeuo63tq+T777DM5ffq0STk/++yzJiOgQVzT0JqOdtPar66IqMvY5suXz6xcp0uy+kv7u1dL1PXtdb9eC3/ZEV0aWMtQsmRJc86WLVuawJvx82uaXhesKlCggFlIx3slvQ0bNsh1111nFiPSmxtd3fK7777L8hrMmzdPbrjhBvN+/uhqj9dff73cd9995gbJvRrdTz/9ZK5ZoUKFpFSpUuam6eDBg+a5WbNmmUWP9PN408/qvrm6WDl18Rt9rDcmAAJH8IftzJw506yG9+2338ro0aNNcF2yZInPMQMHDjS1UA0OumSurnmuKedAaCDU1RvdNXrdHnvssYDLpzccGvTPnz9vUvJjx46VMWPGyA8//CDt2rWTW265RX777TdzrNZKP/jgA1mwYIEJvpqirlSpkt/z6up2Sm8stEzvvvuu3+P0xuidd94x12ndunVSrVo1876HDx/2Oe7pp582ZdPgmCdPHp/V4PSa6Q2L3jSsXbvWrBuvKfSsfPXVV+ZGwh9d6rlDhw6mSWDUqFGe/XrzpTcEejOjZdCbon379pmV/JQ2DWj/Ab0+btqc8tFHH3nKerFy6op3elOh5QMQhGivLARn6969u9WxY0efVfBatmzpc0yTJk2sJ554wvNYv7YPPPCAzzHNmjWzHnzwQfPzsmXLzDFHjhzxPP/999+bfdu2bTOPdUXCIkWKXLR8GY/bvHmzdfnll1uNGzc2j8uWLWsNHz48U3l79eplfn7ooYes66+/3nK5XH7Pr2V67733zM9aNn2sZc3qGp04ccLKmzev9eabb3qeT0tLM+UYPXq0z+f/7LPPPMd89NFHZt/p06fN48KFC1szZsywAqXXYNasWZmuTUJCgtkGDhyY6TXDhg2z2rZt67MvJSXFlGPTpk3msf7O2rdv73l+7NixZvU69/UKpJwNGza0hgwZEvBnAWBZ1PxhO/Xq1fN5rCnzjB3smjdvnulxoDX/YGnzgKatNX1+xRVXmJqm1uBTU1Nl9+7d0qJFC5/j9bG7LJqy1yYHfZ2m6j/99NOwyqLp7XPnzvm8p9aEmzZtmunze19HvYbKfR379esn//d//ydt2rSR559//qJpc23i8Jfy1yyINgdoqj/j+2tWZtmyZebaubcaNWp4Pofq2bOnuSZ//PGHpxOhXjNttgi0nFqGU6dOXfTaAfgLwR+2kzH9rIEgmOFc7vZm79WqNWCGStubNYBr+/XJkyflyy+/lMsvvzyg11555ZWybds2GTZsmAmgmvK+/fbbJaevozuYuq+j9nH4+eefTbpe2+tr1apl0vdZKVGihBw5ciTTfu35r30W9HNq27z3DcCJEydMm7xeO+9Nm0SuueYac4w2CdSvX9+0/2taX8ukwd8tkHJqc8ell14a1rUCnIbgj1xp1apVmR7rGHTlDgTabu6Wcfic9kQPdLy63kxou7p2LNRappv2GdBOgF9//bXP8fpYg5T3cV26dDG1Y+0Fr+31Gdvn3WVSFypX1apVzXHe76k3Ntom7v2egdAbmEcffdTUvG+77TZ5/fXXszxWg/Qvv/zi9znt6Kj9E5o0aWJuANzH6Q2BBm7t46DXz3vTPh1uWrPXGr++v9bwdahgoOU8c+aMyQZo+QAEjuCPXOmtt96S6dOny+bNm2Xw4MGms5z2qlcaXDSAaK1Ra5nagUw7vnnTgKQ1U+0Rr73PQ00bP/7446aTmwZ17dCnHdL0RqNv377m+XHjxsncuXPl119/NWXVcuvIAX9D97T3vt5cuDvGaXNDRho0H3zwQfO+epwGWk2da/m1p30gNAOh10pHBezYscPcSOjNg/vmyR/tUKjD/bKiNwB6U9OsWTNzA6BBv3fv3uYmp2vXrub8GqQXL15sRlp43+D8/e9/9wyj9O6UGEg59aZP3ztjMxCACyP4I1caOnSoGX6m7dqaMtYA6675arrbHXD1eQ3Ozz33XKYe/w888ICpkWumQEcVhELb8bVd+t///rfUrVvXBGTtvV69enVPk4GeW3vKa81Yhxp+/PHHnqYJb9ojX0cHvPzyyyaj0LFjR7/vqW3fOtJBh8Np7XrLli0mqBYrViygMmuq/tChQ9KtWzdTq9amCB2Op9c0K9rrXgO693DBjDQjoUMu9drqDYAGfg3YGujbtm1rrs8jjzxibny8P7/OY6CfR/sEeA9pDKSc+nvWsml/DACBi9Nef0EcD0Sdtl9ru68dprx1Es02aCdHvTmJtNatW0vt2rWDmrBHMzbakVKHEbrnSAAQGGr+AAKi8wboJEWRnEtfOxHqjZym9rWZIBiaRfnPf/5D4AdCQM0fuQ41/9ihfS/0BkAnbQpmoiUA4SH4AwDgMKT9AQBwGII/AAAOQ/AHAMBhCP4AADgMwR8AAIch+AMA4DAEfwAAHIbgDwCAwxD8AQAQZ/n/9j5lI+QqDMAAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 1. Run a sample\n",
        "test_seq = torch.tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 0]]).to(device)\n",
        "model(test_seq)\n",
        "\n",
        "# 2. Access the weights from the first layer's mha module\n",
        "# Shape will be (1, num_heads, seq_len, seq_len)\n",
        "weights = model.layers[0].mha.attn_weights\n",
        "\n",
        "# 3. Average across heads and remove batch dim -> (seq_len, seq_len)\n",
        "attn_map = weights[0].mean(dim=0).cpu().detach().numpy()\n",
        "\n",
        "# 4. Plot\n",
        "plt.imshow(attn_map, cmap='viridis')\n",
        "plt.title(\"Attention Map: Input vs Output\")\n",
        "plt.xlabel(\"Input Positions (Keys)\")\n",
        "plt.ylabel(\"Output Positions (Queries)\")\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mlprep",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
